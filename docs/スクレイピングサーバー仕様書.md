# ウェブスクレイピングAPI エンドポイント仕様書

## エンドポイント一覧

| メソッド | エンドポイント | 説明 |
|---------|--------------|------|
| POST    | /crawl/      | 指定したURLをクロールし、内部リンクとページ構造を抽出する |

## POST /crawl/

### 概要

指定されたURLからクロールを開始し、指定したCSSクラスの要素内の内部リンクを抽出します。また、ページのタイトル、説明、インデックス状態、見出し構造も収集します。

### リクエスト

#### Content-Type
`application/json`

#### リクエストボディ

```json
{
  "start_url": "https://example.com",
  "target_class": "content-area"
}
```

#### パラメータ詳細

| パラメータ名 | 型 | 必須 | 説明 |
|------------|----|----|------|
| start_url  | string | はい | クロールを開始するURL |
| target_class | string | はい | 内部リンクを抽出する対象となるHTML要素のクラス名 |

### レスポンス

#### 成功時のレスポンス (200 OK)

```json
{
  "scraped_data": [
    {
      "current_url": "https://example.com",
      "title": "ページタイトル",
      "description": "ページの説明文",
      "index_status": "index",
      "internal_links": [
        "https://example.com/page1",
        "https://example.com/page2",
        "https://example.com/page3"
      ],
      "headings": [
        {
          "tag": "h1",
          "text": "メインタイトル",
          "children": [
            {
              "tag": "h2",
              "text": "サブタイトル1",
              "children": [
                {
                  "tag": "h3",
                  "text": "小見出し1",
                  "children": []
                }
              ]
            },
            {
              "tag": "h2",
              "text": "サブタイトル2",
              "children": []
            }
          ]
        }
      ]
    },
    // 複数のページがクロールされた場合、同様の構造のオブジェクトが配列内に追加されます
  ],
  "stderr": "Scrapy実行中の標準エラー出力（デバッグ情報）"
}
```

#### レスポンスフィールド詳細

##### `scraped_data` 配列内の各オブジェクト

| フィールド名 | 型 | 説明 |
|------------|----|----|
| current_url | string | クロールされたページのURL |
| title | string | ページのタイトル（<title>タグの内容） |
| description | string | ページの説明（metaタグの「description」属性の内容） |
| index_status | string | ページのインデックス状態（"index"または"noindex"） |
| internal_links | array | ページ内の対象クラス内にある内部リンクのURLリスト |
| headings | array | ページ内の見出し構造（h1〜h4）を階層的に表現したもの |

##### `headings` 配列内の各オブジェクト

| フィールド名 | 型 | 説明 |
|------------|----|----|
| tag | string | 見出しのHTMLタグ（"h1", "h2", "h3", "h4"のいずれか） |
| text | string | 見出しのテキスト内容 |
| children | array | この見出しの子見出しの配列（同じ構造のオブジェクト） |

#### エラー時のレスポンス (400 Bad Request)

必須パラメータが不足している場合：

```json
{
  "detail": "start_url is required"
}
```

または：

```json
{
  "detail": "target_class is required"
}
```

#### エラー時のレスポンス (500 Internal Server Error)

スクレイピング処理中にエラーが発生した場合：

```json
{
  "detail": "Failed to execute Scrapy command: [エラーメッセージ]"
}
```

JSONのデコードに失敗した場合：

```json
{
  "detail": "Failed to decode JSON from Scrapy output"
}
```

### 例

#### リクエスト例

```bash
curl -X POST "http://localhost:8000/crawl/" \
  -H "Content-Type: application/json" \
  -d '{
    "start_url": "https://example.com",
    "target_class": "content"
  }'
```

#### レスポンス例

```json
{
  "scraped_data": [
    {
      "current_url": "https://example.com",
      "title": "Example Domain",
      "description": "This domain is for use in illustrative examples.",
      "index_status": "index",
      "internal_links": [
        "https://www.iana.org/domains/example"
      ],
      "headings": [
        {
          "tag": "h1",
          "text": "Example Domain",
          "children": []
        }
      ]
    }
  ],
  "stderr": "2025-03-20 15:30:45 [scrapy.core.engine] INFO: Spider closed (finished)"
}
```

## レスポンスの構造図

以下は、レスポンスのJSON構造を視覚的に表したものです：

```
{
  "scraped_data": [
    {
      "current_url": "ページURL",
      "title": "ページタイトル",
      "description": "ページ説明",
      "index_status": "index/noindex",
      "internal_links": [
        "リンク1",
        "リンク2",
        ...
      ],
      "headings": [
        {
          "tag": "h1",
          "text": "見出しテキスト",
          "children": [
            {
              "tag": "h2",
              "text": "サブ見出し",
              "children": [
                ...
              ]
            },
            ...
          ]
        },
        ...
      ]
    },
    ...
  ],
  "stderr": "デバッグ情報"
}
```

## 注意事項

1. クロール対象のウェブサイトによっては、robots.txtの設定やサイトのクロールポリシーを尊重する必要があります。

2. 大規模なウェブサイトのクロールは時間がかかる場合があり、APIのタイムアウト設定に注意が必要です。

3. `internal_links`は指定した`target_class`内に存在するリンクのみを抽出します。ページ全体のリンクが必要な場合は、適切な`target_class`を指定してください。

4. レスポンスの`stderr`フィールドには、Scrapyの実行時のログが含まれており、デバッグ目的で使用できます。